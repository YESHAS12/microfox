# Ollama Agent

This is a simple agent powered by Ollama (local LLM).

## How It Works

- Accepts a prompt from the user.
- Sends it to the local model via Ollama.
- Prints the response.

## Usage

Make sure Ollama is running:
